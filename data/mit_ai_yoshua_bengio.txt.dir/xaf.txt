yoshua bengio:
r neural nets for them to really understand sentences which talk about what's going on in the world. And I think we need language input to help provide clues about what high level concepts like semantic concepts should be represented at the top levels of these neural nets. In fact, there is evidence that the purely unsupervised learning of representations doesn't give rise to high level representations that are as powerful as the ones we are getting from supervised learning. And so the the the clues we're getting just with the labels, not even sentences is already very powerful. Do you think that's an architecture challenge or is it a dataset challenge? Neither uh I'm tempted to just end it there. Elaborate ah of course, data sets and architectures are something you want to always play with. But but I think the crucial thing is more the training objectives, the training frameworks, for example, going from passive observation of data to more active agents which um uh learn by intervening in the world. Uh the r