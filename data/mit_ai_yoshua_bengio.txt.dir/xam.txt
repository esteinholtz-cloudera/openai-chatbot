yoshua bengio:
ther to represent everything the network knows and it's not sufficiently factorized. And so I think this is one of the weaknesses of current neon nets that we have to take lessons from classical A I in order to bring in another kind of compositional, which is common in language, for example, and in these rules, but that isn't so native to Neo nets. And on that line of thinking, disentangled representations. So, so let me connect with disentangled representations if you might, if you don't mind. So for many years, I thought, and I still believe that it's really important that we come up with learning algorithms either unsupervised or supervised but or enforcement whatever that build representations in which the uh important factors. Hopefully, causal factors are nicely separated and easy to pick up from the representation. So that's the idea of disentangled representations. It says transform the data into a space where everything becomes easy. We can maybe just learn with linear models about the things we care