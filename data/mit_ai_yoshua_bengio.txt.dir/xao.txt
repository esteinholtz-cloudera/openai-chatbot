yoshua bengio:
 mechanisms that relate those variables to each other. So like the rules, so the rules are neatly separated, like each rule is you know, living on its own. And when I I change a rule because I'm learning, uh it doesn't need to break other rules. Whereas current neon nets, for example, are very sensitive to what's called catastrophic forgetting where uh after I've learned some things and then I learn new things, they can destroy the old things that I had learned, right? If the knowledge was better factorized and, and uh separated disentangled, then you would avoid a lot of that. Now you can't do this in the sensory domain but like a pixel space. But, but my idea is that when you project the data in the right semantic space, it becomes possible to now represent this extra knowledge beyond the transformation from input to representations, which is how representations act on each other and predict the future and so on in a way that can be neatly um disentangled. So now it's the rules that are disentangled from ea