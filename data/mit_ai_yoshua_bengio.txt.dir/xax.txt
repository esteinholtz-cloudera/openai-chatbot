yoshua bengio:
 disagreement is a, is a sign of a good research, good sign. So the idea of bias in the human sense of bias, how do you think about instilling in machine learning, something that's aligned with human values in terms of bias? We intuitively as human beings have a concept of what bias means of what fundamental respect for other human beings means. But how do we instill that into machine learning systems? Do you think? So? I think there are short term things that are already happening and then there are long term things that we need to do in the short term, there are techniques that have been proposed and I think will continue to be improved and maybe alternatives will come up to take data sets in which we know there is bias, we can measure it pretty much any data set where humans are, you know, being observed, taking decisions will have some sort of bias discrimination against particular groups and so on. And we can use machine learning techniques to try to build predictors, classifiers that are going to be les